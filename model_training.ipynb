{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import time\n",
    "import pickle\n",
    "import pyaudio\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features as mfcc\n",
    "from sklearn.mixture import GaussianMixture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "    rows,cols = array.shape\n",
    "    # print(rows)\n",
    "    # print(cols)\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first =0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows-1:\n",
    "                second = rows-1\n",
    "            else:\n",
    "                second = i+j \n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio,rate):\n",
    "    mfcc_feature = mfcc.mfcc(audio,rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)    \n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    # print(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature,delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "\tSAMPLES_NUMBER = 5\n",
    "\tsource = \"training_set\\\\\"   \t\t\t\t\t #trained set path\n",
    "\tdest  =  \"trained_models\\\\\"     \t\t\t\t #destination path to store trained models\n",
    "\ttrain_file = \"training_set_addition.txt\"     #training file with sample names   \n",
    "\tfile_paths = open(train_file,'r')\n",
    "\tcount = 1\n",
    "\tfeatures = np.asarray(())\n",
    "\tfor path in file_paths:    \n",
    "\t\tpath = path.strip()   \n",
    "\t\tprint(path)\n",
    "\t\tsr,audio = read(source + path)\n",
    "\t\tprint(sr)\n",
    "\t\tvector   = extract_features(audio,sr)\n",
    "\t\tif features.size == 0:\n",
    "\t\t\tfeatures = vector\n",
    "\t\telse:\n",
    "\t\t\tfeatures = np.vstack((features, vector))\n",
    "\t\t\n",
    "\t\tif count == SAMPLES_NUMBER:    \n",
    "\t\t\tgmm = GaussianMixture(n_components = 10, max_iter = 300, covariance_type='diag',n_init = 1)\n",
    "\t\t\tgmm.fit(features) \n",
    "\t\t\t\n",
    "\t\t\t# dumping the trained gaussian model\n",
    "\t\t\tpicklefile = path.split(\"-\")[0]+\".gmm\"\n",
    "\t\t\tpickle.dump(gmm,open(dest + picklefile,'wb'))\n",
    "\t\t\tprint('+ modeling completed for speaker:',picklefile,\" with data point = \",features.shape)   \n",
    "\t\t\tfeatures = np.asarray(())\n",
    "\t\t\tcount = 0\n",
    "\t\tcount = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "\tsource   = \"testing_set\\\\\"  #path of test samples\n",
    "\tmodelpath = \"trained_models\\\\\" #path of trained models\n",
    "\ttest_file = \"testing_set_addition.txt\"       #test samples names\n",
    "\tfile_paths = open(test_file,'r')\n",
    "\n",
    "\tgmm_files = [os.path.join(modelpath,fname) for fname in\n",
    "\t\t\t\tos.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\t\n",
    "\t#Load the Gaussian gender Models\n",
    "\tmodels    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "\tspeakers   = [fname.split(\"\\\\\")[-1].split(\".gmm\")[0] for fname in gmm_files]\n",
    "\n",
    "\t# Read the test directory and get the list of test audio files \n",
    "\tfor path in file_paths:   \n",
    "\t\tpath = path.strip()   \n",
    "\t\tprint(f\"Test File : {path}\\n\")\n",
    "\t\tsr,audio = read(source + path)\n",
    "\t\tvector   = extract_features(audio,sr)\n",
    "\t\tlog_likelihood = np.zeros(len(models)); \n",
    "\t\tmax_score=-100\n",
    "\t\tfor i in range(len(models)):\n",
    "\t\t\tgmm    = models[i]  #checking with each model one by one\n",
    "\t\t\tscores = np.array(gmm.score(vector))\n",
    "\t\t\tif scores > max_score:\n",
    "\t\t\t\tmax_score = scores\n",
    "\t\t\tprint(gmm_files[i].split(\"\\\\\")[-1])\n",
    "\t\t\tprint(scores)\n",
    "\t\t\tlog_likelihood[i] = scores.sum()\n",
    "\t\twinner = np.argmax(log_likelihood)\n",
    "\t\tprint(\"\\tdetected as - \", speakers[winner])\n",
    "\t\tprint(f\"MaxScore = {max_score}\")\n",
    "\t\tprint(\"-\"*50)\n",
    "\t\tif max_score > -24:\n",
    "\t\t\tprint(\"In Group\")\n",
    "\t\telse :\n",
    "\t\t\tprint(\"Other\")\n",
    "\t\tprint(\"#\"*50)\n",
    "\t\ttime.sleep(1.0)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
